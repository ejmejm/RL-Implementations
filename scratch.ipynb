{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_agent(agent_id, create_env, gen_act, mb, n_episodes=4, max_steps=500, render=False):\n",
    "    env = create_env()\n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        mb.start_rollout(agent_id)\n",
    "        for step in range(max_steps):\n",
    "            act = gen_act([obs])\n",
    "            \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            obs_next, rew, d, _ = env.step(act)\n",
    "            \n",
    "            mb.record(agent_id, obs, act, rew)\n",
    "            obs = obs_next\n",
    "            \n",
    "            if d:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(mpmb, n_threads=7, n_episodes=4, return_rewards=False, reset_mem=True):\n",
    "    agent_pool = []\n",
    "    \n",
    "    for i in range(n_threads):\n",
    "        agent_pool.append(Thread(target=spawn_agent, args=(i, make_lunar_lander_c, network.gen_act, mpmb),\n",
    "                                                     kwargs={'n_episodes': math.ceil(n_episodes/n_threads)}))\n",
    "        agent_pool[-1].start()\n",
    "\n",
    "    for agent in agent_pool:\n",
    "        agent.join()\n",
    "        \n",
    "    \n",
    "    if return_rewards:\n",
    "        return mpmb.get_avg_reward(), mpmb.to_data(reset=reset_mem)\n",
    "    return mpmb.to_data(reset=reset_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpmb = MTMemoryBuffer()\n",
    "# ep_rewards = []\n",
    "\n",
    "# for i in range(n_episodes//update_freq):\n",
    "# #     ep_reward, train_data = gather_data(mpmb, n_episodes=update_freq, return_rewards=True)\n",
    "# #     ep_rewards.append(ep_reward)\n",
    "#     spawn_agent(0, make_cart_pole, network.gen_act, mpmb, n_episodes=update_freq, max_steps=300, render=False)\n",
    "#     print(mpmb.get_avg_reward())\n",
    "#     train_data = mpmb.to_data()\n",
    "#     network.train(train_data)\n",
    "# #     if i % print_freq == 0 and i != 0:\n",
    "# #         print(f'Update #{int(i)}, Recent Reward:', np.mean(ep_rewards[print_freq:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
