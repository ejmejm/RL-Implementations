{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import MTMemoryBuffer\n",
    "from policies import PPOTrainer\n",
    "from utils import gaussian_likelihood, reshape_train_var\n",
    "import tensorflow as tf\n",
    "from tensorflow.layers import dense, conv2d, max_pooling2d, flatten\n",
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "from env import CartPoleEnv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CartPoleEnv()\n",
    "\n",
    "obs = tf.placeholder(tf.float32, shape=[None]+list(env.observation_space.shape))\n",
    "dense1 = dense(obs, 32, activation=tf.tanh)\n",
    "dense2 = dense(dense1, 32, activation=tf.tanh)\n",
    "act_probs = dense(dense2, env.action_space.shape[0])\n",
    "\n",
    "v_dense1 = dense(obs, 32, activation=tf.tanh)\n",
    "v_dense2 = dense(v_dense1, 32, activation=tf.tanh)\n",
    "value = dense(v_dense2, 1)\n",
    "\n",
    "network = PPOTrainer(obs, act_probs, value, act_type='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = MTMemoryBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = EnvController(CartPoleEnv, mb, n_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45540, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.576586484909058"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = time.time()\n",
    "ec.sim_thread(1, network, 1000)\n",
    "print(mb.to_data().shape)\n",
    "time.time() - tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46309, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.376994848251343"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = time.time()\n",
    "ec.sim_episodes(network, 1000)\n",
    "time.time() - tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 30.95636796951294\n",
      "2 : 13.943068504333496\n",
      "3 : 14.795561790466309\n",
      "4 : 14.825214862823486\n",
      "5 : 15.121448278427124\n",
      "6 : 15.156155586242676\n",
      "7 : 15.415870189666748\n",
      "8 : 15.219146013259888\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    ec = EnvController(CartPoleEnv, mb, n_threads=i)\n",
    "    tmp = time.time()\n",
    "    ec.sim_episodes(network, 1000)\n",
    "    print(i, ':', time.time() - tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class EnvController():\n",
    "    def __init__(self, make_env, memory_buffer, n_threads=1, obs_transform=None, act_transform=None):\n",
    "        self.make_env = make_env\n",
    "        self.mb = memory_buffer\n",
    "        self.n_threads = n_threads\n",
    "        if obs_transform is not None:\n",
    "            self.obs_transform = obs_transform\n",
    "        if act_transform is not None:\n",
    "            self.act_transform = act_transform\n",
    "        \n",
    "    def obs_transform(self, obs):\n",
    "        return obs.squeeze()\n",
    "    \n",
    "    def act_transform(self, act):\n",
    "        return act\n",
    "    \n",
    "    def set_obs_transform(self, transform_func):\n",
    "        self.obs_transform = transform_func\n",
    "    \n",
    "    def set_act_transform(transform_func):\n",
    "        self.act_transform = transform_func\n",
    "        \n",
    "    def sim_thread(self, agent_id, network, n_episodes=1, max_steps=200, render=False):\n",
    "        env = self.make_env()\n",
    "        \n",
    "        for episode in range(n_episodes):\n",
    "            self.mb.start_rollout(agent_id)\n",
    "            obs = env.reset()\n",
    "            for step in range(max_steps):\n",
    "                obs = self.obs_transform(obs)\n",
    "                act = network.gen_act(obs)\n",
    "                act = self.act_transform(act)\n",
    "\n",
    "                obs_next, rew, d, _ = env.step(act)\n",
    "\n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(0.02)\n",
    "\n",
    "                mb.record(agent_id, obs, act, rew)\n",
    "                obs = obs_next\n",
    "\n",
    "                if d:\n",
    "                    break\n",
    "                    \n",
    "    def sim_episodes(self, network, n_episodes=1, max_steps=200, render=False):\n",
    "        threads = []\n",
    "        ept = [int(n_episodes // self.n_threads) for i in range(self.n_threads)] # Episodes per thread\n",
    "        ept[:(n_episodes % self.n_threads)] += np.ones((n_episodes % self.n_threads,))\n",
    "        for i in range(self.n_threads):\n",
    "            new_thread = threading.Thread(target=self.sim_thread, args=(i, network, int(ept[i]), max_steps,))\n",
    "            threads.append(new_thread)\n",
    "            new_thread.start()\n",
    "            \n",
    "        for thread in threads:\n",
    "            thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn_agent(agent_id, create_env, network, mb, n_episodes=4, max_steps=500, render=False):\n",
    "    env = create_env()\n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        mb.start_rollout(agent_id)\n",
    "        for step in range(max_steps):\n",
    "            act = network.gen_act([obs])\n",
    "            \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            obs_next, rew, d, _ = env.step(act)\n",
    "            \n",
    "            mb.record(agent_id, obs, act, rew)\n",
    "            obs = obs_next\n",
    "            \n",
    "            if d:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(mpmb, n_threads=7, n_episodes=4, return_rewards=False, reset_mem=True):\n",
    "    agent_pool = []\n",
    "    \n",
    "    for i in range(n_threads):\n",
    "        agent_pool.append(Thread(target=spawn_agent, args=(i, make_lunar_lander_c, network.gen_act, mpmb),\n",
    "                                                     kwargs={'n_episodes': math.ceil(n_episodes/n_threads)}))\n",
    "        agent_pool[-1].start()\n",
    "\n",
    "    for agent in agent_pool:\n",
    "        agent.join()\n",
    "        \n",
    "    \n",
    "    if return_rewards:\n",
    "        return mpmb.get_avg_reward(), mpmb.to_data(reset=reset_mem)\n",
    "    return mpmb.to_data(reset=reset_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpmb = MTMemoryBuffer()\n",
    "# ep_rewards = []\n",
    "\n",
    "# for i in range(n_episodes//update_freq):\n",
    "# #     ep_reward, train_data = gather_data(mpmb, n_episodes=update_freq, return_rewards=True)\n",
    "# #     ep_rewards.append(ep_reward)\n",
    "#     spawn_agent(0, make_cart_pole, network.gen_act, mpmb, n_episodes=update_freq, max_steps=300, render=False)\n",
    "#     print(mpmb.get_avg_reward())\n",
    "#     train_data = mpmb.to_data()\n",
    "#     network.train(train_data)\n",
    "# #     if i % print_freq == 0 and i != 0:\n",
    "# #         print(f'Update #{int(i)}, Recent Reward:', np.mean(ep_rewards[print_freq:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
